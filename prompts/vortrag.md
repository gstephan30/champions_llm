## Inhalt
1. Einstieg KI
2. Funktionsweise von LLMs
3. Agenten & Tools
4. Pro & Contra GenAI
5. Nutzung & Einsichten
6. Fazit & Guidance

---

## Einstieg: Interaktive Beispiele

### Eisverkauf am Strand
| Verkauft (Zielvariable) | Temperatur (Â°C) | Wochenende | Regen (mm) | Schulferien |
|---:|---:|:--:|---:|:--:|
| **?** | 31 | Ja | 0 | Ja |
| 166 | 28 | Ja | 1 | Nein |
| 30 | 20 | Nein | 5 | Nein |
| 204 | 32 | Ja | 0 | Nein |
| 145 | 25 | Nein | 0 | Ja |

ðŸ‘‰ Aufgabe: SchÃ¤tzen Sie den fehlenden Wert.

---

### Pendelzeiten
| Entfernung (km) | Fahrzeit (min) | Verkehrslage |
|---:|---:|:--:|
| 12 | 30 | Stau |
| 25 | 55 | Stau |
| 12 | 24 | Kein Stau |
| 25 | 45 | Kein Stau |
| 15 | 30 | **?** |

ðŸ‘‰ Aufgabe: Bestimmen Sie die Verkehrslage.

---

### Pendelzeiten (mit Kontext: Wochentag)
| Entfernung (km) | Fahrzeit (min) | Wochentag | Verkehrslage |
|---:|---:|:--:|:--:|
| 12 | 30 | Di | Stau |
| 25 | 55 | Mo | Stau |
| 12 | 24 | So | Kein Stau |
| 25 | 45 | Sa | Kein Stau |
| 15 | 30 | Sa | **Kein Stau** |

ðŸ‘‰ Regel: **Wochenende = Kein Stau**, **Werktag = Stau**

---

## Sprachmodelle: SatzergÃ¤nzung
- "Alles hat ein Ende, nur die Wurst hat ____."  
- "Ende gut, alles ____."  
- "Der Apfel fÃ¤llt nicht weit vom ____."  
- "Wir laufen auf die ____."  

---

## Sprachmodelle: SatzergÃ¤nzung mit Wahrscheinlichkeiten
- â€žWir laufen auf die â€¦â€œ
   - StraÃŸe â€” 25 %
   - Wiese â€” 20 %
   - BÃ¼hne â€” 15 %
   - Alm â€” 30 %
   - Wand â€” 10 %

**Mit Kontext: Bayern**
- Alm â€” 60 %
- StraÃŸe â€” 10 %
- Wiese â€” 15 %
- BÃ¼hne â€” 5 %
- Wand â€” 10 %

---

## Abgrenzung

### Klassische KI â€“ Statistik & ML
- Regressionen, EntscheidungsbÃ¤ume, Clusteranalysen, Kundensegmentierung, ROI â€¦
- Sentimentanalyse, Topic Modelling
- ZuverlÃ¤ssig, kontrollierbar, auf Unternehmensdaten zugeschnitten
- Hauptproblem: **DatenqualitÃ¤t**

### LLMs
- Generalisten, trainiert auf riesigen Datenmengen
- Generierung von Text, Bildern, Videos, Audio, Code â€¦
- MÃ¤chtig, aber fehleranfÃ¤llig & datenschutzkritisch
- Hauptproblem: **Privacy & Governance**

---

## Beispiel RissprÃ¼fung â€“ Feature Importance
[SHAP Bild]

---

## Wie funktionieren LLMs?

### Beispiel: Sentimentanalyse
Original: â€žDer Film war unglaublich langweilig und eine totale EnttÃ¤uschung.â€œ

1. **Stopwords entfernt**: â€žFilm unglaublich langweilig totale EnttÃ¤uschungâ€œ
2. **WÃ¶rter mit Sentimentwerten**:
   - langweilig â†’ -0.7  
   - EnttÃ¤uschung â†’ -0.8  
3. **Gesamt-Score**: -1.6 â†’ Ergebnis: **negativ**

---

## Beispiel LSW
- StÃ¶rberichte Walzwerk â€“ LSW
   - Cluster-Algorithmen â†’ Klassische KI
   - Zero Shot Klassifizierung â†’ Transformer
- Texterkennung â€“ MAU
   - Vortrainiertes Modell (LSTM â†’ Deep Learning)

---

## Wie funktionieren LLMs?
- Texte â†’ **Tokens** ([Tokenizer-Demo](https://huggingface.co/spaces/Xenova/the-tokenizer-playground))
- **Attention-Mechanismus**: relevante WÃ¶rter werden stÃ¤rker gewichtet
- Beispiel: â€žDie Hauptstadt von Deutschland ist ____.â€œ â†’ wichtig: *Hauptstadt*, *Deutschland*

---

## Was ist ChatGPT, Gemini, Meta AI, Grok?
Ein **Agent** ist ein System, das:
1. seine **Umgebung wahrnimmt** (Input),
2. eine **Entscheidung trifft** (Policy),
3. eine **Aktion ausfÃ¼hrt** (Output).

---

## Agent-Beispiel: JARVIS
- â€žBring mir bitte ein Glas Wasser.â€œ
- Wahrnehmung: hÃ¶rt die Anfrage
- Entscheidung: â€žWo sind Wasser und GlÃ¤ser?â€œ
- Aktion: geht in die KÃ¼che, bringt Wasser

Mit mehr Tools (SchlÃ¼ssel, Drohne â€¦) kann er mehr Probleme lÃ¶sen â€“ oder neue schaffen (*Ultron*).

---

## Infrastruktur: Agent-Loop
**ReAct-Schema:**
- Thought â†’ Action â†’ Observation â†’ Answer

ðŸ‘‰ Typische Tools: Websuche, Zusammenfassung, Bildgenerator

---

## Tools
- Hugging Face: https://huggingface.co/models
- Frage: **Welche Tools haben Sie schonmal eingesetzt?**

---

## Agent ChatGPT & Co.
Beispielauftrag: â€žRecherche zu *aktuellen COâ‚‚-MaÃŸnahmen im EAF-Stahl* (2024â€“2025).â€œ
- LLM liest, versteht Kontext, verteilt Aufgaben
- Sammelt Quellen, priorisiert, fasst zusammen, erstellt Roadmap

---

## Pro vs. Contra GenAI

### Chancen
- Vielseitig, Automatisierung
- UnterstÃ¼tzung im Alltag & Beruf
- Breite Anwendbarkeit

### Grenzen
- Bias & Halluzinationen
- Datenschutz & Compliance
- Transparenz
- AbhÃ¤ngigkeit von US-Firmen
- Kosten & Energieverbrauch

---

## Energiekosten & Vergleich
| Modell / Szenario | COâ‚‚ (Tonnen) | Strom (kWh) | Kosten (â‚¬) |
|-------------------|--------------|-------------|------------|
| GPT-4 Training | 12.500â€“15.000 | 52â€“62 Mio | 7,8â€“9,3 Mio |
| Gemini Training | 9.000â€“13.000 | 35â€“45 Mio | 5,3â€“6,8 Mio |
| KÃ¼hlschrank/Jahr | â€“ | 200â€“300 | 60â€“90 |
| EAF Stahl/Jahr | 123.200 | 308 Mio | 46,2 Mio |

Quelle: Google, Epoch, Industrie-Vergleich

---

## Einsichten

### 1) Nutzung & Wachstum
- 1,5 Mio. Konversationen (Mai 2024 â€“ Juni 2025)
- Wachstum: 451 Mio â†’ 2,6 Mrd Nachrichten/Tag
- Work vs. Non-Work: Freizeitnutzung von 53 % â†’ >70 %
- 700 Mio WAU (Juli 2025), stÃ¤rker in mittleren/niedrigen Einkommen; Gender-Gap schrumpft

### 2) Haupt-Use-Cases
- Practical Guidance, Seeking Information, Writing â‰ˆ 78 %
- Programmieren nur 4,2 %
- Pro Nutzer steigen Nachrichten/Tag â†’ Lerneffekt + bessere Modelle

### 3) Risiken & Kritik
- Jugendschutz: Stanford warnt vor KI-Companions fÃ¼r Kinder
- Arbeitsbedingungen: Content-Moderation teils < $2/h, psychische Belastung
- Sicherheit & Ethik: Jailbreaks wirksam; Therapie-Ersatz nur Randthema (1,9 % Nutzung)

Quelle: Washington Post, Stanford, OpenAI

---

## Fazit
- **KI nutzen â€“ aber mit gesundem Menschenverstand & Verantwortung.**
- Immer kritisch prÃ¼fen, Datenschutz beachten, strukturiert vorgehen

ðŸ‘‰ Frage ans Publikum: **Wer hat privat schon ChatGPT oder Copilot genutzt?**

---

## Guidance
- Normaler Prompt-Aufbau: Rolle, Problem, Ziel â†’ bedanken
- Mit Checkliste arbeiten
- Prompts speichern (txt oder md)
- Klar strukturiert, Satzzeichen, keine Tippfehler
- JSON-Formate nicht zwingend besser
